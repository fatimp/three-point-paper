\documentclass[reprint,amsmath,amssymb,aps,pre,showkeys,showpacs]{revtex4-1}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[export]{adjustbox}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
\newcommand{\highlight}[1]{{\color{red}{#1}}} % convinient for revised version

\begin{document}
\preprint{APS/123-QED}

\author{Vasily~Postnicov\textsuperscript{1,3}}
\author{Marina~V.~Karsanina\textsuperscript{1,2}}
\author{Aleksey~Khlyupin\textsuperscript{1,2}}
\author{Kirill~M.~Gerke\textsuperscript{1,2}}
\email{kg@ifz.ru}

\affiliation{\textsuperscript{1}Moscow Institute of Physics and Technology,
  Dolgoprudny, 141701, Russia}
\affiliation{\textsuperscript{2}Schmidt Institute of Physics of the Earth of
  Russian Academy of Sciences, Moscow, 107031, Russia}
\affiliation{\textsuperscript{3}Dokuchaev Soil Science Institute, Moscow, 119017, Russia}

\title{Evaluation of 3-point correlation functions from structural images on CPU
  and GPU architectures: accounting for anisotropy effects}

\begin{abstract}
Structures, or spatial arrangements of matter and energy, including some fields
(e.g., velocity or pressure) are ubiquitous in research applications and
frequently require description for subsequent analysis, or stochastic
reconstruction from limited data.  The classical descriptors are 2-point
correlation functions (CFs), but the computation of 3-point statistics is known
to be advantageous in some cases as they can probe non-Gaussian signatures, not
captured by their 2-point counterparts. Moreover, $n$-point CFs with $n \ge 3$
are believed to possess larger information content and provide more information
about studied structures. In this paper, we have developed algorithms and code
to compute $S_3, C_3, F_{sss}, F_{ssv}$ and $F_{svv}$ with a right-angle and arbitrary
triangle pattern. The former was believed to be faster to compute, but with the help of precomputed
regular positions we achieved the same speed for arbitrary pattern. In this work we also 
implement and demonstrate computations of directional 3-point CFs -- for this
purpose right-triangular pattern seems to be superior due to explicit orientation and high coverage.
Moreover, we assess the errors in CFs' evaluation due to image or pattern rotations and show that they 
have minor effect on accuracy of computations.
The execution times of our algorithms for the same number of samples are orders of
magnitude lower than in existing published counterparts. We showed that the volume
of data produced get unwieldy very easily, especially if computations are
performed in frequency domain. For these reasons until information content of
different sets of correlation functions with different "n-pointness" is not
known, advantages of CFs with $n>3$ are not clear. Nonetheless, developed
algorithms and code are universal enough to be easily extendable to any $n$
(with increasing computational and RAM burden). All results are available as
part of open source package \code{CorrelationFunctions.jl} [Postnicov et al.,
  2024, Comp.Phys.Commun., 299, 109134]. As described in this paper, 3-point CFs
computations can be immediately applied in a great number of research
applications, for example: 1) flow and transport velocity fields analysis or any
data with non-Gaussian signatures, 2) deep learning for structural and physical
properties, 3) structure taxonomy and categorization.  In all these and numerous
other potential cases the ability to compute directional 3-point functions may
be crucial. Notably, the organization of the code functions allows computation
of cross-correlation, i.e., one can compute 3-point CFs for multiphase images
(while binary structures were used in this paper for simplicity of
explanations).
\end{abstract}

%\keywords{Arrays, multiplication, addition}

\maketitle

\section{Introduction}
\label{sec:intro}
Structures, or spatial arrangements of matter and energy, including some fields
(e.g., velocity or pressure) are ubiquitous in research applications and
frequently require description for subsequent analysis. Examples of such objects
for studies include galaxy formations \cite{springel2006}, immiscible multiphase
fluid flow patterns \cite{hopkins2015new,balashov2021}, rock and soil samples
\cite{rozenbaum2014,karsanina2015,ledesma2018,chen2020super,prokhorov2021digital,vogel2010},
food specimens \cite{derossi2019,nagdalian2021}, biological tissue
\cite{park2020}, vortexes during flow \cite{gorbunova2016precessing} and
interstellar turbulence \cite{portillo2018developing}. The scale of interest may
span orders of magnitude from angstroms and nm for materials
\cite{garum2020,gerke2021,khlyupin2023molecular} to millions of light-years for
star clusters \cite{takada2003three,hopkins2013stars}. The studied structure can
be non-static -- it will change with time, and this dynamics is usually also of
great interest \cite{jiao2013,fomin2023soil}. Thus, description of the structure
is of utmost importance for numerous applications:
\begin{enumerate}
  \item Elucidation of structure--property relationships in the form of
    theoretical expression \cite{Torquato_book,Sahimi_book}, e.g., rigorous
    bounds and such;
  \item Prediction of material physical properties using machine (deep) learning
    \cite{obayashi2018persistence,kamrava2020linking,roding2020predicting};
  \item Description of complex structures and fields for taxonomy, comparison
    and analysis
    \cite{takada2003three,hopkins2013stars,shivashankar2015felix,saadatfar2017pore,
      portillo2018developing,cheng2022data,KarsaninaEJSS,PNM_Morse,khlyupin2023molecular},
    which may include temporal dynamics or surface evolution
    \cite{jiao2013,PhysRevE.92.023301,prokhorov2022,chen2022,fomin2023soil};
  \item Morphological representativity
    \cite{capek2009,rozenbaum2014,gerke2019tensor,zubov2024search} and spatial stationarity
    analysis \cite{REVpaper,LavrukhinPRE,zubov2024search};
  \item Stochastic reconstructions from limited amount of input data
    \cite{Adler_recon,Y-T,tahmasebiPRL,Euras2012,EPL2,karsaninaPRL,rozanski2023}
    in the form of limited dimension structures or correlation functions;
  \item Compress structural information for storage, analysis, training (feature
    extraction), and retrieval (by means of stochastic reconstructions)
    \cite{jiao2007,SciRep1,Havelka,KarsaninaEJSS};
  \item Multiscale image fusion that is usually necessary due to trade-off
    between field-of-view and imaging resolution
    \cite{SciRep1,Geoderma2018,chen2020super,yan2023multiscale,karimpouli2022,yan2024modeling}.
\end{enumerate}

The number of possible descriptors to quantify spatial structure developed
within different disciplines is stunning, for example: phase ratio or porosity
\cite{anovitz2015characterization}, surface area, radial distribution functions
\cite{zimm1948scattering,becker2010radial}, Minkowski functionals
\cite{vogel2010} and tensors \cite{schroder2011minkowski}, correlation functions
\cite{Torquato_book}, persistence diagrams
\cite{shivashankar2015felix,saadatfar2017pore,obayashi2018persistence,zubov2024search}. The
evolution of such metrics was mainly induced by the ease of measurement and
interpretation. In fact, we need a single universal descriptor defined by only
one characteristic -- information content. The latter is an ability of the
metric to describe the structure at hand with 100\% meaning the ability to
fully recover the structure back from this metric. Thus, universal descriptor
has to possess following key properties: (1) high information content, (2) ease
of assess, (3) high compression ratio (i.e., descriptor is much "smaller" than
the structure itself).

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.8\linewidth]{images/3point.png}
  \caption[]{A schematic representation of a binary porous media (pores are
    shaded) with examples of CFs computations (all classic two- and three-point
    correlation functions are presented according to the legend on the left
    side). Computations take into account all possible configurations of a line
    segment which either make a contribution to the CF (conventionally shown as
    ``CF = 1'') or do not make a contribution (``CF = 0'').}
  \label{fig:3point-scheme}
\end{figure*}
The large portion of the research papers mentioned above
\cite{rozenbaum2014,karsanina2015,ledesma2018,derossi2019,portillo2018developing,
  takada2003three,hopkins2013stars,jiao2013,Torquato_book,roding2020predicting,
  KarsaninaEJSS,capek2009,gerke2019tensor,REVpaper,LavrukhinPRE,Adler_recon,Y-T,
  tahmasebiPRL,Euras2012,EPL2,karsaninaPRL,jiao2007,SciRep1,Havelka,Geoderma2018}
is based on so-called correlation functions (CFs). Majority of these functions, with 
surface functions being a notable exception \cite{samarin2023robust}, define a
probability that some events are occurring withing the structure (with some
special cases of surface functions), for example, 2-point probability $S_2$
measures the probability that both ends of the line segment are within the same
phase, 2-point cluster function $C_2$ -- that both ends of the line segment are
within the same interconnected cluster of same phase, and lineal path $L_2$
measures the probability that the whole segment lies within the phase (see
\cref{fig:3point-scheme}). Compared to other descriptors, CFs possess a number
of features making them, in our opinion, a perfect candidate for universal
descriptor:
\begin{enumerate}
  \item They contain the majority of other metrics inside. For example, porosity
    is $S_2(0)$ (and at zero correlation length of the majority of correlation
    functions except for surface ones), surface area is represented by in the
    derivative at $S_2(0)$ \cite{debye1957scattering}. Connectivity is described by cluster
    functions $C_2$ or $C_3$. Pore-size distribution is related to pore-size
    function and partially by $L_2$ and $S_3$. Surface-void functions are
    interconnected with mean curvature and Euler characteristic
    \cite{ma2020generation}. Altogether, the classic set of correlation
    functions describes both the geometry and topology of the structure at hand;
  \item While the extent to which such classical set describes any arbitrary
    structure is not yet known, compared to other complex descriptors where are
    known pathways to assess the information content of correlation functions --
    there is a methodology for $S_2$ \cite{Gommes2} and approaches for other
    functions \cite{Degeneraty.045306,CHERKASOV2024129400};
  \item In addition to a possibility to compute correlation functions using
    images or other structural data, i.e., similar to all other descriptors,
    some CFs can be also determined experimentally
    \cite{debye1957scattering,barrall1992nmr,dietrich1995scattering,li2018accurate};
  \item Correlation functions can be scaled \cite{karsaninaPRL} or manipulated,
    for example, to add functions into a single structure \cite{moctezuma2002};
  \item As opposed to scalar metrics such as porosity, surface area or Minkowski
    functionals, CFs can be computed in directions and describe anisotropic
    structures;
  \item Numerous rigorous bounds to obtain thermal, elastic, electromagnetic and
    transport properties are known, among which the most known (and least useful
    due to the impractically huge gap between the bounds) are Hashin-Strikman
    bounds \cite{hashin1963variational}. Other expressions based on integration
    of higher order $S_n$ are known and were found to be closer to direct
    simulations
    \cite{brown1955solid,beran1965use,milton1981bounds,hlushkou2015effective};
  \item One can control both the size of the CFs-based descriptor and the
    information content via correlation length, number of functions in the set
    (including directions \cite{EPL2}), and by the order of functions (e.g., 2-
    and 3-point versions, or even more points).
\end{enumerate}
This list highlights that correlations functions are indeed possess necessary
properties so satisfy key criteria stated above.

However, while 2-point CFs are computed and used in multitude of studies, higher
order functions, for example, 3-point correlation functions are not that widely
used. The reason for this is straightforward -- 3-point correlation functions
are more involved and, thus, require much more computational resources to
assess. It has been shown that the amount of additional information content decreases with
each increase in number of points $n$ \cite{yao1993high,Gommes2}. The
trade-off between additional information and computational burden is still not
clear. Nonetheless, the computation of 3-point statistics is known to be
advantageous at least in the number of applications as related to cosmology,
astrophysics and turbulence patterns analysis as they can probe non-Gaussian
signatures in the distribution of matter and energy, which are not captured by their
2-point counterparts
\cite{TakadaJain,hopkins2013stars,gorbunova2016precessing,yoo2022non}.

In this contribution we continue our initiative to develop a simple, efficient
and open-source solution to compute all classical correlation functions on CPU
and GPU architectures -- \code{CorrelationFunctions.jl} \cite{CFsjlpaper}. Here
we build upon previous results in computations of higher order functions with
$n > 2$, most notably by Malmir et al. \cite{malmir2018}, and our aim is to
develop robust and computationally efficient methods. In addition, we also
considered the case of anisotropic structures and how to describe them with
3-point correlation functions similar to directional 2-point CFs
\cite{10.1063/1.4867611,EPL1}.

The paper is organized as follows: in \cref{sec:methods} we provide
mathematical background and describe methods for computation of 3-point
correlation functions. Verification of these methods along with some results for
real-world samples (sandstone, soil, etc.) is described in
\cref{sec:results}. Section \ref{sec:discussion} provides the discussion, a
comparison with other existing methods and summarizes possible directions for
future research.

\section{Methods}
\label{sec:methods}
\subsection{3-point correlation functions}
Let $A_1, A_2, \dots, A_n$ be pairwise disjoint subsets of a set
$A \subset \mathbb{R}^m$, where the index can be interpreted as a phase on the
image $A$. We introduce a family of indicator functions
$I_n(x) : A \rightarrow \{0,1\}$ defined as:
\begin{equation}
  I_n(x) = \left\{
  \begin{array}{ll}
    1 & \quad x \in A_n \\
    0 & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation}

Now we can define the three-point correlation function
$S_3: \mathbb{R}^{2m} \rightarrow [0, 1]$:
\begin{equation}
  S_3^n(x_1, x_2) = \langle I_n(x) I_n(x + x_1) I_n(x + x_2) \rangle
\end{equation}
where $\langle \dots \rangle$ means ensemble average. It can be understood as
the probability that all three vertices of a triangle $(0, x_1, x_2)$ will
appear in the subset $A_n$ when the triangle is randomly thrown in $A$. When $A$
represent isotropic medium, $x_1$ and $x_2$ can be replaced with three numbers
$r_1 = |x_1|$, $r_2 = |x_2|$ and $r_3 = |x_2 - x_1|$ to get a function of three
scalar arguments.

Another function closely related to the three-point correlation function is the
cluster function which can be defined as:
\begin{equation}
  C_3^n(x_1, x_2) = \sum_{k=1}^K \langle I_n^k(x) I_n^k(x + x_1) I_n^k(x + x_2) \rangle
\end{equation}
where $I_n^k$ is an indicator function for $k$-th cluster of $A_n$ and $K$
is a total number of clusters. A cluster is a subset of $A_n$ such that any two
points in this subset can be connected with a curve belonging to that subset.

By introducing a function $M_n(x) = |\nabla I_n(x)|$ which is a so-called interface
indicator function, we can define three additional
correlation functions -- these are the surface-surface-surface function
($F_{sss}$), surface-surface-void function ($F_{ssv}$) and surface-void-void
function ($F_{svv}$). They are defined as:
\begin{align}
  F_{sss}^n(x_1, x_2) &= \langle M_n(x) M_n(x + x_1) M_n(x + x_2) \rangle \\
  F_{ssv}^n(x_1, x_2) &= \langle M_n(x) M_n(x + x_1) I_{(void)}(x + x_2) \rangle \\
  F_{svv}^n(x_1, x_2) &= \langle M_n(x) I_{(void)}(x + x_1) I_{(void)}(x + x_2) \rangle
\end{align}
Here $I_{(void)}$ is an indicator function for the subset of the void phase
$A_v$. Unlike $S_3$ and $C_3$ functions, these functions do not have the meaning
of probability and have the units of measurement inversely proportional to
volume, surface and length, respectively (e.g., can be measured in $\mu m^{-3}$,
$\mu m^{-2}$ and $\mu m^{-1}$ or other convenient units depending on the problem
to be solved).  These functions describe the interface of the subset $A_n$ and
its spatial configuration with respect to $A_{(void)}$.

When a phase of interest is clear from the context or irrelavant a superscript
can be omitted from mathematical notation of correlation functions.

\subsection{Computational algorithms}
Three-point correlation function $S_3$ can be computed either in spatial domain
or in frequency domain via the convolution theorem. Suppose that a finite
countable set $A$ is defined as a multidimensional array. A point $x$ belongs to
a subset $A_n$ if and only if $A[x] = n$. The simplest algorithm below
calculates $S_3$ pointwise in the spatial domain:
\begin{algorithmic}[1]
  \Procedure{$S_3$}{$A, n, x_1, x_2$}
  \State $A_n \gets I_n (A)$
  \Comment Apply $I_n$ to the input array elementwise.
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A''_n \gets \mathfrak{S}_{x_2}(A_n)$
  \State $Tmp \gets A_n \cdot A'_n \cdot A''_n$
  \State \textbf{return} $Sum(Tmp) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}
In this algorithm the indicator function $I_n$ for the phase of interest $n$ is
applied to the input array $A$. Then the shift operator $\mathfrak{S}$ is used
to shift $A_n$ by vectors $x_1$ and $x_2$. Finally, the three arrays are
multiplied pointwise and a normalized sum of all elements of the product is
returned.

There are two common boundary conditions when applying $\mathfrak{S}$. The
first condition is to extend $A_n$ periodically (\cref{fig:s3-periodic}) when
accessing out-of-bounds array elements. In this case $\mathfrak{S}_z$ is a
circular shift operator (here ``$x \mod y$'' means a vector
$(x_1 \mod y_1, x_2 \mod y_2, \dots)$):
\begin{equation}
  A[x] \leftarrow A[x+z \mod shape(A)]
\end{equation}
In this case $Norm(A, x_1, x_2)$ does not depend on $x_1$ and $x_2$ and
is equal to the total number of elements in $A$. The second condition is to
replace out-of-bound elements with zeros (so-called zero padding)
(\cref{fig:s3-zeros}). A formula for $Norm(A, x_1, x_2)$ in this case is in Appendix
\ref{sec:number-of-trials} and $\mathfrak{S}_z$ is defined as follows:
\begin{equation}
  A[x] \leftarrow \left\{
  \begin{array}{ll}
    A[x+z] & \quad \text{if $x+z$ is a correct index in $A$} \\
    0 & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation}
\begin{figure*}[tp]
  \centering
  \subfigure[Periodic boundary conditions]{
    \includegraphics[width=0.4\linewidth]{images/periodic.png}
    \label{fig:s3-periodic}}
  \hfill
  \subfigure[Zero padding]{
    \includegraphics[width=0.4\linewidth]{images/zeros.png}
    \label{fig:s3-zeros}}
  \caption[]{Computation of unnormalized $S_3$ function at point $(1, 2)$ for
    one-dimensional sequence of length 8.}
  \label{fig:s3-computation}
\end{figure*}

The second approach is to compute the whole correlation map in the Fourier
domain. Suppose we have a function
$f: \mathbb{R} \rightarrow \mathbb{R}$. Triple correlation for this function is:
\begin{equation}
  g(t_1, t_2) = \int f(\tau) f(\tau + t_1) f(\tau + t_2) d \tau.
\end{equation}
We can use a well-known formula to compute Fourier image of $g$:
\begin{equation}
  \hat{g}(z_1, z_2) = \hat{f}(z_1) \hat{f}(z_2) \overline{\hat{f}(z_1 + z_2)}
\end{equation}
This algorithm has a better computational complexity compared with the previous
algorithms if the whole correlation map is needed ($O(n^2 \log n)$ vs
$O(n^3)$ where $n$ is a number of elements in the input array). The whole
correlation map, however, requires a lot of memory and is rarely
needed. Imagine, that the input array $A$ is of dimensions $500 \times 500$.
Then, considering that single precision floating point numbers are used,
$4 \cdot 2 \cdot 500^4 / 1000^3 = 500$ GB are needed to store Fourier image of
the map. Moreover, Fourier image of the whole map has to be computed even if only one
element of the map in spatial domain is required. The aforementioned limitations
render this approach impractical.

Algorithms for three-point surface functions are the same as for $S_3$,
containing only small modifications. The main difference is that we need to
replace an indicator function $I_n$ with an edge detection operator $E_n$
(see Appendix \ref{sec:filter}). Then the algorithms are straightforward:
\begin{algorithmic}[1]
  \Procedure{$F_{sss}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A''_n \gets \mathfrak{S}_{x_2}(A_n)$
  \State $Tmp \gets A_n \cdot A'_n \cdot A''_n$
  \State \textbf{return} $Sum(Tmp) / Norm(A, x_1, x_2)$
  \EndProcedure

  \Procedure{$F_{ssv}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A_{(void)} \gets I_{(void)} (A)$
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A'_{(void)} \gets \mathfrak{S}_{x_2}(A_{(void)})$
  \State $Tmp \gets A_n \cdot A'_n \cdot A'_{(void)}$
  \State \textbf{return} $Sum(Tmp) / Norm(A, x_1, x_2)$
  \EndProcedure

  \Procedure{$F_{svv}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A_{(void)} \gets I_{(void)} (A)$
  \State $A'_{(void)} \gets \mathfrak{S}_{x_1}(A_{(void)})$
  \State $A''_{(void)} \gets \mathfrak{S}_{x_2}(A_{(void)})$
  \State $Tmp \gets A_n \cdot A'_{(void)} \cdot A''_{(void)}$
  \State \textbf{return} $Sum(Tmp) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}

Input images must have appropriately high resolution for edge detection filter
to work correctly. A criterion for ``goodness'' of an image can be expressed
with $Q_\alpha$ parameter \cite{samarin2023robust}. Let $\alpha \in [0, 1]$
and $f(x)$ be (band-limited) input image ($x \in \mathbb{R}^2$ or
$\mathbb{R}^3$). We define $Q_\alpha$ as follows:
\begin{equation}
  \begin{aligned}
    f_0(x) &= f(x) - \langle f(x) \rangle \\
    Q_\alpha &= \frac{\int_{-\alpha\omega}^{\alpha\omega} |\hat{f_0}(z)|^2
      dz}{\int_{-\omega}^{\omega} |\hat{f_0}(z)|^2 dz}
  \end{aligned}
\end{equation}
where $\hat{f_0}$ is a Fourier transform of $f_0$ and $\omega$ is a folding
frequency which depends only on resolution of the image. If a criterion
$Q_{0.5} > 0.97$ holds then the image is suitable for application of
aforementioned algorithms for calculation of surface functions, otherwise
image's resolution can be improved with the help of interpolation prior to
computations \cite{samarin2023robust}.

To compute $C_3$ function we need to use a connected-component labeling
algorithm \cite{4728561,PhysRevB.14.3438} to label clusters. Then, again, a
slightly modified algorithm for $S_3$ is used to assess cluster function:
\begin{algorithmic}[1]
  \Procedure{$C_3$}{$A, n, x_1, x_2$}
  \State $A_n \gets I_n (A)$
  \State $C_n \gets \mathfrak{C}(A_n)$
  \State $C'_n \gets \mathfrak{S}_{x_1}(C_n)$
  \State $C''_n \gets \mathfrak{S}_{x_2}(C_n)$
  \State $Tmp \gets C_n \odot C'_n \odot C''_n$
  \State \textbf{return} $Sum(Tmp) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}
Here $\mathfrak{C}$ is connected-component labeling operator and $\odot$ is
defined as follows:
\begin{equation}
  x \odot y = \left\{
  \begin{array}{ll}
    1 & \quad x = y \ne L_{(void)} \\
    0 & \quad \text{otherwise}.
  \end{array}
  \right.
\end{equation}
where $L_{(void)}$ is a label of the void phase.

\subsection{Triangular sampling pattern}
There are three major known sampling pattern implementations reported in the literature (\cref{fig:pattern}):
\begin{enumerate}
  \item Arbitrary pattern (or random) triangle is thrown into the structure (e.g., \cite{malmir2018});
  \item Web-like predefined triangular pattern (e.g., \cite{SMITH1988176});
  \item Right-triangular sampling pattern (e.g., \cite{dimitrakopoulos2010high}).
\end{enumerate}
The second case of the web-like pattern was useful at times of low computational resources and seems to be the least flexible in terms of structure coverage. Right-traingle as a pattern was popular due ease of implementation and potential speed gains due to vectorization.
However, we have organized the algorithms of \code{CorrelationFunctions.jl} to be able to utilize any patterns.
This was achieved by organizing computational functions not around a shifting pattern, but rather around precomputed points representing
triangle's vertices -- thus making our approach under the hood using the ideas behind the web-like pattern method. 

This is implemented in our code by using the same interface for all computation functions to assess CFs:
\begin{verbatim}
corrfn(input, phase, ps1, ps2)
\end{verbatim}
where \code{corrfn} stands for \code{s3} ($S_3$), \code{c3} ($C_3$),
\code{surf3} ($F_{sss}$) etc., \code{input} is the input array describing the structure, \code{phase} is
a phase of interest and \code{ps1} and \code{ps2} are arrays of points in which
correlation function is calculated. Firstly, \code{corrfn} does all necessary
preparations for the input array (e.g. edge extraction or connected component
labeling) and then calculates the correlation function for each pair of
arguments from \code{ps1} and \code{ps2}.

To compare different approaches in this work we performed calculations with right-triangular\cite{dimitrakopoulos2010high,malmir2018},
equilateral triangle and isosceles triangle with varying angle \cite{SMITH1988176,malmir2018} patterns -- both with averaging
over the whole structure, or computed in directions (see next two subsections below). In the first case the pattern where arguments
of a correlation function $x_1$ and $x_2$ are fixed to be parallel to one of the
axes $X$, $Y$ or $Z$ with restriction $x_1 \perp x_2$ (\cref{fig:pattern}, right scheme). Except for equilateral triangle, the output  has dimensions $D_1 \times D_2$ where $D_1$ and $D_2$ are dimensions of the input array along selected axes. For equilateral pattern there is a single curve (i.e.,
similar to $S_2$ graphical representation).

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.8\linewidth]{images/web-like.png}
  \caption[]{Schematic representation of patterns for 3-point correlation functions evaluation:
  arbitrary or random triangle, web-like, and right-triangular patterns. Note that real patterns are
  more complex and are made simple for visualization, i.e., for right-triangular pattern we sample
  all possible variations between points. Equilateral or isosceles triangles can be considered
  as arbitrary patterns and can be either fixed in space, or rotated randomly.}
  \label{fig:pattern}
\end{figure*}

\subsection{Analysis of anisotropic media}
When an analyzed sample is anisotropic, i.e., it is stretched or oriented along
some specific direction, it may be beneficial to align one of the sides (cathetus for the right-triangular pattern) of
sampling triangle \cref{fig:pattern} with that direction. In this case the
anisotropy present in the sample will be properly captured by computed 3-point
correlation function.

To detect the direction of anisotropy we use an $N \times N$ (where $N$ is
dimensionality of the sample) covariance matrix
$\Sigma = \left\{ \sigma_{ij} \right\}$ for coordinates of points in the phase of
interest:
\begin{equation}
  \sigma_{ij} = \sum_{x \in \left\{
    \begin{array}{l}
      \text{Coordinates of points} \\
      \text{in the phase of interset}
    \end{array}
    \right\}} (x_i - \overline{x_i})(x_j - \overline{x_j})
\end{equation}
and decompose $\Sigma$ as $T \Lambda T^{-1}$ where $T$ is a unitary matrix and
$\Lambda$ is diagonal. $T$ can always be made so that it defines a rotation (by
multiplication of one of the columns by $-1$ if needed, so that
$\det T = 1$). Application of this rotation to the sample (or its inverse to the
pattern) makes the direction of anisotropy coaligned with the pattern, so
anisotropy can be better represented in the correlation function. For the sake
of visual clarity in this study we choose to rotate the image instead of the
pattern (\cref{fig:aniso}). Any rotation can potentially reduce accuracy of
computed functions due to necessity to interpolate the image during
rotation, and this important issue is explored later.
\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.8\linewidth]{images/fig_rot.png}
  \caption{Examples of directional analysis of images with the help of $S_3$ function
    when dealing with highly anisotropic media. The right-triangular pattern (\cref{fig:pattern}, right side)
    which we use in our algorithm is most sensitive to anisotropy which is
    directed along one of the axes. \\
    From top down, left to right: an original image of an anisotropic pore; a
    rotated image of the pore, so it is positioned along the major axis; $S_3$ function
    for the original pore; $S_3$ function for the rotated pore with a vector
    $(0.92, -0.4)$ being a direction of elongation of the pore; $S_3$ function
    averaged across rotations similar to previously known algorithms
    \cite{berryman1988,SMITH1988176,malmir2018}.}
  \label{fig:aniso}
\end{figure*}

\subsection{Directional and averaged computations}
When a sample is known to be isotropic, the correlation function may be
calculated multiple times, each time applying a random rotation to the sample or
the pattern, and then averaged across rotations to gather more statistics. This
process is illustrated on \cref{fig:workflow}. This way we obtain similar
results to sampling procedures used in
\cite{berryman1988,SMITH1988176,malmir2018}.

Another approach is to fix a number of directions, for example, orthogonal and
diagonal ones \cite{EPL1,EPL2,CFsjlpaper}. In other words, the sample is rotated
with periodic boundary conditions to orient along predefined directions. After
each rotation we compute correlation functions as described above and obtain a
number of matrices $D_1 \times D_2$ that are then stacked to represent 3-point
correlation functions computed in directions \cref{fig:workflow}.

To summarize, \code{CorrelationFunctions.jl} allows to compute 3-point
correlation functions averaged in all directions (by randomly rotating the
sample or the pattern), along predefined number of directions (e.g., orthogonal
and diagonal by rotation in these directions) or along the direction of major
anisotropy (that can be determined using \code{$detect\_anisotropy$} function).
Full correlation map for 3-point functions is impractical due its huge size and, thus,
is not implemented.

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.6\linewidth]{images/workflow.png}
  \caption[]{A possible workflow for computation of correlation functions
    (clockwise from top left to bottom right ): 1.~rotating a sample in random
    directions (which is equivalent to rotating the sampling pattern),
    2.~calculating the correlation function for each direction, 3.~avegaring
    results across rotations, 4.~representing the result as a family of 2D
    plots.}
  \label{fig:workflow}
\end{figure*}

\section{Results}
\label{sec:results}
\subsection{Verification}
To verify correctness of computation of $S_3$ and $C_3$ functions we use the
following simple relations:
\begin{align}
  S_3^n (x, 0) = S_3^n (0, x) &= S_2^n(x) \\
  C_3^n (x, 0) = C_3^n (0, x) &= C_2^n(x) \\
  \lim_{\substack{x_1 \to \infty \\ x_2 \to \infty}} S_3^n (x_1, x_2) &= \phi_n^3
\end{align}
Here $\phi_n$ is a fraction of phase $n$ in $A$.

There are only few sets for which analytic expressions for $S_2$ are known. One
of those is a set consisting of overlapping balls with a fixed radius $R$ and
centers generated with Poisson process with parameter $\lambda$. In this case
the expression for $S_2$ is the following:
\begin{equation}
  \begin{aligned}
    S_2(r, R) &= \exp(-\frac{4}{3}\pi\lambda R^3 f(r, R)) \\
    f(r, R) &= \left\{
    \begin{array}{ll}
      1 + \frac{3}{4} \frac{r}{R} - \frac{1}{16} (\frac{r}{R})^3 & \quad r < 2R \\
      2 & \quad \text{otherwise}.
    \end{array}
    \right.
  \end{aligned}
  \label{eq:s2-balls}
\end{equation}

On \cref{fig:balls} there is an intersection of such a set with $R = 0.02$ and
$\lambda=5000$ within a cube $[0, 1]^3$. Because $R \ll 1$, we can use
\cref{eq:s2-balls} to verify our computations -- this is exactly what we present on
\cref{fig:balls-s3-comparison}.
\begin{figure*}[tp]
  \centering
  \subfigure[Realization of overlapping balls]{
    \includegraphics[width=0.4\linewidth]{images/balls.png}
    \label{fig:balls}}
  \hfill
  \subfigure[A plot of $S_3(0, r)$ computed with our algorithm and a theoretical
    formula.]{
    \includegraphics[width=0.4\linewidth]{images/balls-s3.png}
    \label{fig:balls-s3-comparison}}
  \caption[]{A comparison of calculated and theoretical values of $S_3$ function
    for overlapping balls.}
  \label{fig:s3-verification}
\end{figure*}

To test $F_{sss}$ function we use a recently developed approach which computes
that function for sets defined by inequality $f(x) \le U$, $x \in \mathbb{R}^3$
with help of automatic differentiation \cite{postnicov20232}. We choose $f$ as:
\begin{equation}
  f(x, y, z) = y^2 + z^2 - a x^2 (b^2 - x^2)
\end{equation}
and parameters $a = 10$, $b = 0.45$, $U = 10^{-2}$, so inequation
$f(x, y, z) \le U$ gives us a dumbbell-like object (\cref{fig:sss-dumbbell}).

The test is performed by firstly evaluating the inequation in a cube
$[-1, 1]^3$ and obtaining precise values of $F_{sss}$ and secondly computing
$F_{sss}$ with our algorithm, giving a discretized volume of $400^3$
voxels as the input. For ease of comparison, $F_{sss}$ function is evaluated within $XY$
plane. Pointwise relative error of $F_{sss}$ is on
\cref{fig:sss-dumbbell-error}. Maximal relative error in the area distanced
farther than 0.1 (20 pixels) from curves of discontinuity (see
\cref{fig:sss-dumbbell-precise}) is no more than 20\%.
\begin{figure*}[tp]
  \centering
  \subfigure[The dumbbell-like object used in testing of $F_{sss}$ computation]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell.png}
    \label{fig:sss-dumbbell}}
  \hfill
  \subfigure[Relative error of computation]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-err.png}
    \label{fig:sss-dumbbell-error}}
  \vskip\baselineskip
  \subfigure[$F_{sss}$: precise. The correlation function is undefined (has type
    II discontinuity) at curves A, B and C.]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-precise.png}
    \label{fig:sss-dumbbell-precise}}
  \hfill
  \subfigure[$F_{sss}$: calculated with our approach]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-julia.png}}
  \caption[]{A comparison of $F_{sss}$ function calculated using our algorithm
    with its precise values.}
  \label{fig:sss-verification}
\end{figure*}

To test $F_{ssv}$ and $F_{svv}$ we use the following relations for such a set
$A$ where all non-void phase is covered by a ball with radius $R$:
\begin{align}
  F^n_{ssv}(x_1, x_2) &= F^n_{ss}(x_1) \qquad x_2 > R \\
  F^n_{svv}(x_1, x_2) &= F^n_{sv}(x_1) \qquad x_2 > R
\end{align}
$F_{ss}$ and $F_{sv}$ functions are well-known for a ball of radius $R$ (solid
phase) placed in the center of cube of volume $V$ (void phase):
\begin{align}
  F_{ss}(r, R) &= \frac{1}{V} \left\{
    \begin{array}{ll}
      2\pi R^2/r & \quad r < 2R \\
      0 & \quad \text{otherwise}
    \end{array}
    \right.\\
  F_{sv}(r, R) &= \frac{1}{V} \left\{
    \begin{array}{ll}
      \pi Rr + 2\pi R^2 & \quad r < 2R \\
      4\pi R^2 & \quad \text{otherwise}
    \end{array}
    \right.
\end{align}
The comparison of our algorithm against theory is shown on
\cref{fig:surface-verification}. Radius of the ball is chosen to be $R=0.2$.
\begin{figure*}[tp]
  \centering
  \subfigure[$F_{ssv}$]{
    \includegraphics[width=0.4\linewidth]{images/ball-ssv.png}
    \label{fig:balls-ssv}}
  \hfill
  \subfigure[$F_{svv}$]{
    \includegraphics[width=0.4\linewidth]{images/ball-svv.png}
    \label{fig:ball-svv}}
  \caption[]{Comparison of $F_{ssv}$ and $F_{svv}$ functions for a ball with the
    radius $0.2$ with theoretical values.}
  \label{fig:surface-verification}
\end{figure*}

\subsection{Comparison of sampling patterns}
\label{sec:compare_patterns}
To compare different sampling and averaging patterns we performed computations of $S_3$ on Sandstone 3D sample.
They were performed in three different manners: 1) isosceles triangle with a right-triangle
between the equal side -- this sampling resembles both our right-triangle pattern and pattern
of Malmir et al. \cite{malmir2018}, computations were made within XY planes within the image and, thus,
represent directional CF; 2) equilateral triangle with side $r$ directionally analyzed within XY planes;
3) equilateral triangle with side $r$ averaged over 20 random rotations -- reminiscence of web-like and random patterns.

The results of the comparison are shown in \cref{fig:comparison_patterns}. For isotropic samples curves for
directional and ensemble averaged, as well as for right-angle isosceles triangle, basically collapse to each other
with minimal differences.
\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.8\linewidth]{images/fig_compar.png}
  \caption[]{A comparison of computations of $S_3$ correlation function for the Sandstone sample
  using different patterns with and without random rotations. Left: evaluated with isosceles triangle 
  pattern with the side $r$ and the angle between edges $\phi$; sampling triangles are aligned with the plane XY.
  Middle: evaluated with equilateral triangle pattern with the side $r$; sampling triangles are aligned with the plane XY.
  Right: evaluated with equilateral triangle pattern with the side $r$. The result is averaged over 20 
  random rotations of the sampling triangle. Lower image: comparison of $S_3$ functions calculated with 
  right triangle pattern with length of the both catheti $r$ and equilateral triangle pattern 
  (both averaged over rotations and aligned with the plane XY).}
  \label{fig:comparison_patterns}
\end{figure*}

A Jupiter notebook presenting all these cases is available online \cite{Repo_example} and is a good example of
applications of our package, especially in terms of establishing \code{ps1} and \code{ps2}
arrays for arbitrary triangle patterns (isosceles and equilateral cases in our example),
and for directional and ensemble averaged calculations.


\subsection{Applications to material images}

\begin{table*}[!htp]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    Sample name & Image type & Dimensions (pixels/voxels) & Image resolution ($\mu m$)
    & $Q_{0.5}$ \\
    \hline
    Sandstone & XCT &  $500 \times 500 \times 500$ & 2.25 & 0.9703 \\
    Soil & Reconstruction & $500 \times 500 \times 500$ & 0.72 & 0.9431 \\
    Shale & Reconstruction & $160 \times 160 \times 160$ & 2.25 & 0.8912 \\
    Sandstone & SEM &  $1280 \times 869$ & 0.10 & 0.9613 \\
    \hline
  \end{tabular}
  \caption{Summary of samples used for calculation of correlation functions.}
  \label{tab:summary}
\end{table*}
In this section we compute correlation functions for 2- and 3-dimensional porous
media samples. Table \ref{tab:summary} contains information about these
samples. Note that we compute surface correlation functions only for those
samples for which the criterion $Q_{0.5} > 0.97$ holds (the two sandstones and
the soil) \cite{samarin2023robust}. Images of the samples are presented on
\cref{fig:samples}. On plots of correlation functions for isotropic samples we
provide a family of curves with the first argument of the correlation function
being fixed. For anisotropic samples we provide heatmaps of correlation
functions where anisotropy can be easily observed.
\begin{figure*}[tp]
  \centering
  \subfigure[Sanstone XCT]{
    \includegraphics[width=0.4\linewidth]{images/15581.png}
    \label{fig:sample-sandstone-xct}}
  \hfill
  \subfigure[Sandstone SEM (different clusters of void phase are shown in color)]{
    \includegraphics[width=0.4\linewidth, frame]{images/sandstone1.png}
    \label{fig:sample-sandstone}}
  \vskip\baselineskip
  \subfigure[Soil]{
    \includegraphics[width=0.4\linewidth]{images/soil.png}
    \label{fig:sample-soil}}
  \hfill
  \subfigure[Shale]{
    \includegraphics[width=0.4\linewidth]{images/shale.png}
    \label{fig:sample-shale}}
  \caption[]{Images of samples used for calculation of higher-order correlation
    functions.}
  \label{fig:samples}
\end{figure*}

Correlation functions for the XCT sample of a sandstone are on
\cref{fig:sample-sandstone-xct-cf}. The plot of $S_3$ function allows us to
estimate porosity of the sample to be $\sim 0.19$ (note that the curve with
$r_1 = 0$ is actually $S_2$ function). The two-point correlation function
reaches plateau at $r_2 \approx 60 \mu m$ which means that two events
of finding two points in the void phase are independent if the points are
farther than $60 \mu m$ from each other. We see that the sample is isotropic
($S_3(0, 56.25) \approx S_3(56.25, 0)$). From similarity of the $C_3$ and $S_3$
functions it can be stated that the pore phase in this sample forms one big
interconnected pore system.

Correlation functions for the SEM sample (the sandstone) are on
\cref{fig:sample-sandstone-cf}. Porosity of the sample is $\sim 0.3$ as follows
from the plot of $S_3$ function at $r_1 = 0$. The function $S_3(0, r_2)$ reaches
plateau at $r_2 \approx 20\ \mu m$. The sample is highly anisotropic (elongated
along the ordinate). The samples have clusters which are $\sim 45\ \mu m$ in
diameter.

The anisotropic samples (the soil and the shale) were preliminarily rotated with
periodic boundary conditions to align elongated pores with coordinate
axes. Rotated samples are presented on \cref{fig:samples-rot} and heatmaps of
$S_3$ function for these samples -- on \cref{fig:heatmaps}. Based on the
analysis of correlation functions it is evident that elongated clusters of the
void phase within the Soil sample form a structure which resembles a regular
grid with spacing of about $60 \mu m$. The sample of shale shows less regular
yet still anisotropic structure. We provide the rest of correlation functions
for the sample of soil on \cref{fig:soil-maps}.

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.4\linewidth]{images/15581-surf3.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/15581-surf2void.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/15581-surfvoid2.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/15581-s3.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/15581-c3.png}
  \caption[]{Correlation functions for the sandstone XCT sample
    (\cref{fig:sample-sandstone-xct}).}
  \label{fig:sample-sandstone-xct-cf}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-surf2void.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-surfvoid2.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-s3.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-c3.png}
  \caption[]{Correlation functions for the sandstone SEM sample
    (\cref{fig:sample-sandstone}).}
  \label{fig:sample-sandstone-cf}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \subfigure[Soil]{
    \includegraphics[width=0.4\linewidth]{images/soil-rot.png}}
  \hfill
  \subfigure[Shale]{
    \includegraphics[width=0.4\linewidth]{images/shale-rot.png}}
  \caption[]{Rotations of anisotropic samples with pores aligned with the
    coordinate axes.}
  \label{fig:samples-rot}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.4\linewidth]{images/soil-s3.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/shale-s3.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/soil-avg.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/shale-avg.png}
  \caption[]{Heatmaps of $S_3$ function for highly anisotropic samples. On the
    left: soil, on the right: shale. On the top: the function calculated for a
    rotation of the sample which aligns the direction of anisotropy with the
    axes, on the bottom: the function averaged across 100 random rotations.}
  \label{fig:heatmaps}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \subfigure[$C_3$]{
    \includegraphics[width=0.4\linewidth]{images/c3-map.png}}
  \hfill
  \subfigure[$F_{sss}$]{
    \includegraphics[width=0.4\linewidth]{images/surf3-map.png}}
  \vskip\baselineskip
  \subfigure[$F_{ssv}$]{
    \includegraphics[width=0.4\linewidth]{images/surf2void-map.png}}
  \hfill
  \subfigure[$F_{svv}$]{
    \includegraphics[width=0.4\linewidth]{images/surfvoid2-map.png}}
  \caption[]{Correlation maps for the cluster function and the surface functions
    of the sample of soil. The functions are calculated for a rotation of the
    sample which aligns the direction of anisotropy with the axes.}
  \label{fig:soil-maps}
\end{figure*}

\subsection{Execution times for our algorithms}
In this section we assess execution times of proposed computational algorithms
for random 3-dimensional arrays of bits (i.e. each element can be either 0 or
1). For ease of analysis, the arrays have the equal number of elements along
each direction therefore representing cubes of binary porous media. The number
of voxels $V$ in each cube increases from $1.25 \cdot 10^5$ to $2.7 \cdot 10^7$
linearly. Times of execution are measured separately for each function executed
on a CPU and a GPU. Hardware and software components used for testing are listed
in \cref{tab:machine}. Each computation of a correlation function is equivalent
to throwing of $V^{5/3}$ pattern triangles into the sample.
\begin{table*}[!htp]
  \centering
  \begin{tabular}{|c|c|}
    CPU & Intel Xeon Gold 6248R @ 3GHz \\
    RAM & 1TB DDR4-2933 \\
    GPU & Nvidia Tesla V100 with 16 GB of RAM \\
    Julia & 1.9.3 \\
    CorrelationFunctions.jl & 0.10.3
  \end{tabular}
  \caption{Parameters of the machine used to measure execution times of the
    algorithms described in this paper.}
  \label{tab:machine}
\end{table*}
\begin{figure*}[tp]
  \centering
  \subfigure[CPU]{
    \includegraphics[width=0.4\linewidth]{images/timings-cpu.png}}
  \hfill
  \subfigure[GPU]{
    \includegraphics[width=0.4\linewidth]{images/timings-gpu.png}}
  \caption[]{Execution times of the algorithms proposed in this paper.}
  \label{fig:timings}
\end{figure*}

Wall times are shown in \cref{fig:timings}. They do not depend on the type of sampling pattern used. It can be seen that the time of
execution is a power function of voxels number. GPU gives a
10x-100x performance boost depending on the correlation function. Note that
random pixel/voxel patterns are a hard test for some functions, especially for
$C_3$, as it produces a huge number of separate clusters. Thus, for real samples
execution times can be even smaller compared to those reported on \cref{fig:timings}.

Direct comparison against existing modern approaches, namely described by Malmir
et al. \cite{malmir2018} and by Sun et al. \cite{sun2022third}, is not always
straightforward due to algorithmic differences.  In particular, the latter cited
work computes 3-point correlation functions for sphere packings in the
continuous domain; however, on a GPU it takes approximately 28 hours to perform
$2\times10^6$ samplings (see Table 1 in \cite{sun2022third}).  Considering
verification results in \cref{sec:results}, it seems that it would be much
faster to discretize the sphere packing with appropriate $Q_{0.5} > 0.97$ and to
utilize our package to assess correlation functions within tens of minutes
without any loss in accuracy.  For $S_3$ and 3-point surface functions, Malmir
et al. reported computation times of a couple of minutes for a $128^3$ voxels 3D
image with $2\times10^5$ samples on CPU (see section IV in \cite{malmir2018}).
In our case, we sample $\approx 31\times10^9$ triangles within 2 sec on CPU, and
less than a second on GPU.  Our implementation of $C_3$ is even more performant
compared to existing counterparts.

\section{Discussion}
\label{sec:discussion}
In this contribution we have presented two approaches to compute three-point correlation
function $S_3$ which is used as a basis to assess $C_3, F_{sss}, F_{ssv}$ and $F_{svv}$:
\begin{enumerate}
\item Computation in frequency domain using Fourier transform. This approach has
  computational complexity $O(n^2 \log n)$ and computes the whole correlation
  map. Unfortunately, it requires $O(n^2)$ additional memory and therefore can
  be used only with small inputs. Moreover, the whole Fourier image of the input
  is needed even if only a small portion of the correlation map is of interest.
\item Computation in spatial domain. This approach is implemented in
  \code{CorrelationFunctions.jl} package. This approach calculates the full map with
  complexity $O(n^3)$ but uses only $O(n)$ additional memory for shifted
  versions of the input. For our purposes the whole map is not needed and
  therefore the amount of calculations can be significantly reduced.
\end{enumerate}
It's tempting to create an algorithm which unites advantages of both approaches
(fast speed of the first and low memory consumption of the second) to
compute some desired slices of the full correlation map. It is known that Fourier
transform is the only linear transform which allows computation of convolution
in linear time. It is still an open question if there are linear transforms which
allow computation of convolution faster than a naïve approach
\cite{stone2008uniqueness,stone1998convolution}.

We have made execution time comparisons of our algorithm with existing
algorithms.  However, it is also beneficial to compare some algorithmic details
against existing digital approaches -- proposed by Malmir~et.~al.
\cite{malmir2018} and another one by Smith and Torquato \cite{SMITH1988176}. The
first algorithm generates a triangle with fixed sides $r_1$ and $r_2$ and an
arbitrary angle $\theta$ between them and places it in the medium firstly making
a random translation and a rotation around a random vector by a random angle. By
making a large number of trials the algorithm gets a value of a three-point
correlation function at the point $(r_1, r_2, \theta)$. The second algorithm
takes a precalculated triangle $(r_1, r_2, \theta)$ from a web-like pattern and
places it in the medium without rotation, only applying a random
translation. This way the algorithm preserves orientation of triangles stored in
the pattern. The main advantage of our approach that can operate on arbitrary patterns is in
its parallelizability and ease of implementation. The rotations necessary
for arbitrary placement of the pattern within the image can be random as in the Malmir et al. algorithm, or it
can be a single rotation to align the sampling triangle with the
direction of anisotropy (\cref{fig:aniso}). The latter allows computing
directional 3-point correlation functions for anisotropic structures similar to
2-point counterparts \cite{10.1063/1.4867611,EPL1}.

As was mentioned in the \cref{sec:intro} section, computation of 3-point
correlation functions can be beneficial for some applications, yet the trade-off
between computational/storage burden due to higher orders and information
content is still not clear. The same goes for representation of the correlation
functions -- either in the form of averaged or directional functions, or as a
full correlation map. The latter is larger than the original image and was found
beneficial only in a limited number of applications, for example, in 3D
stochastic reconstructions from 2D cuts
\cite{cherkasov2021adaptive}. Computation of 3-point functions for 3D image even
along a single direction with a simplified pattern in the form of right-angle
triangle produces a 2D matrix similar in size to a 2D cut through the sample at
hand \cref{fig:workflow}. Averaging over a huge number of directions produces
the same volume of data, but looses all information about directional
differences within the structure. Computation of CFs with n > 3 results in
multidimensional matrices larger than the 3D image. The only way to keep this
profusion of floats at bay is to utilize the pattern that can be described with
a single parameter while shifting without rotations
\cite{chen2019hierarchical,chen2022}. In this fashion the results can be still
represented by a single function similar to 2-point CFs. But weather this
approach produces the descriptors with higher information content is an open
question.  In light of this discussion, at this point we decided to limit
\code{CorrelationFunctions.jl} with $n=3$, keeping in mind that extension of our
algorithms to $n>3$ for $S_n, C_n, F_{s...s}$ and $F_{s...v}$ is actually not
that complicated \cite{dimitrakopoulos2010high}.

The question if image rotation affects the quality of computations remains open.
To answer this question we performed a study on value noise images.
In \cref{sec:rotqua} we demonstrate that even nearest-neighbor
interpolation results only in insignificant loss of quality. Rotation of the
pattern has same drawbacks related to interpolation of the sample which are most
noticeable at small correlation lengths. The both methods (rotation of the
sample or the pattern) produce nearly equivalent result if the sample is
homogeneous and an average pore size is much less than the sample's size (see
\cref{sec:rotrot}).

Another interesting question is which sampling pattern is more powerful?
Our results shown in \cref{fig:comparison_patterns} clear illustrate that
for isotropic structure all sampling techniques provide quite similar results.
The differences, of course, will be significant for isotropic cases and
directional 3-point CFs calculations. Again, the clear winner here is not obvious.
Right-triangular pattern allows to systematically sample the structure with
predefined direction. On the other hand, equilateral triangle allows to
minimize the volume of computed functions and represent them as single curve,
similar to 2-point functions. Random pattern could be useful for rigorous bounds.
So, the better approach can depend on the problem at hand. Nonetheless,
the direct comparison of patterns can be performed only on the basis of
information content -- something we discuss in the next paragraph.

We mentioned that classic set of correlation functions describes both the
geometry and topology of the structure at hand -- but this is to yet unknown
extent. With the advent of analytical methods \cite{CHERKASOV2024129400} to
assess information content of arbitrary descriptor for structure of any size, it
will be possible to choose the most useful set of correlation functions and
compare their information content against classical and other metrics. If
computationally effective methodology for information content assessment will be
developed, it should amend all aforementioned uncertainties and provide a clear
winner -- a plethora of different 2-point CFs or a less numerous set of
higher-order functions. Such long awaited answer would not be universal thought
and depends not only on descriptor's information content versus data volume
ratio, but also on its applicability to solve particular problems. For example,
it is well known that cluster $C_2$ function provides a lot of information in
addition to $S_2$ \cite{JiaoPNAS}, yet it's application in stochastic
reconstructions is very limited due to computational burden of cluster
relabeling during annealing \cite{karsanina2015}. Still, effective information
content assessment techniques will provide a possibility to account for such
additional application constraints.

As described in this paper, 3-point CFs computations can be immediately applied
in a great number of research applications, for example: 1) flow and transport
velocity fields analysis or any data with non-Gaussian signatures, 2) deep
learning for structural and physical properties (at least to observe the
differences between 2-point and 3-point based training datasets), 3) structure
taxonomy and categorization. In all these and numerous other potential cases the
ability to compute directional 3-point functions may be crucial. Notably, the
organization of the code functions for 3-point CFs computation is similar to
those previously developed for 2-point functions \cite{CFsjlpaper}, thus,
allowing computation of cross-correlation, i.e., one can compute 3-point CFs for
multiphase images (while binary structures were used in this paper for
simplicity).

\section{Summary}
In this paper, we have considered the problem of computing n-point correlation
functions, namely $S_n, C_n, F_{s...s}$ and $F_{s...v}$, for which
computationally efficient algorithms can be developed (including computations on
GPU). For $n=3$ we have developed code in Julia language to compute $S_3, C_3,
F_{sss}, F_{ssv}$ and $F_{svv}$ in an arbitrary set of points. We also provide a
function which generates a right-angle triangle pattern which can be useful for
directional CFs evaluation. Computations are easily
vectorized and utilize the power of modern CPU and GPU architectures. The
execution times for the same number of sample are orders of magnitude lower than
existing published counterparts. We showed that the volume of data produced get
unwieldy very easily, especially if computations are performed in frequency
domain. For these reasons until information content of different sets of
correlation functions with different "n-pointness" is known, it is seemingly no
much reason to increase the number of points. Nonetheless, developed algorithms
and code are universal enough to be easily extendable to any $n$ (with
increasing computational and RAM burden). All results are available as part of
open source package \code{CorrelationFunctions.jl}, developed by our group and
freely available to the public with numerous Jupiter notebooks showing examples
of applications to assess 3-point correlation functions for 2D and 3D images.

\section{Acknowledgements}
This research was supported by the Russian Science Foundation grant 23-74-00061.

Collaborative effort of the authors within the FaT iMP (Flow and Transport in Media with Pores) research group
and used some of its software. We thank our colleague Konstantin Romanenko for suggestions and administrative work.

\appendix
\section{Computation of number of trials for non-periodic mode}
\label{sec:number-of-trials}
If the displacement vectors $x_1, x_2: x_1 \perp x_2$ are parallel to two
distinct unit vectors $i=(1,0,0)$, $j=(0,1,0)$ or $k=(0,0,1)$ then the number of
trials for the input array having dimensions $D = (D_x, D_y, D_z)$ is the
following:
\begin{equation}
  \begin{aligned}
    & Norm(A, x_1, x_2) = \prod_k D'_k \\
    & D' = D - x_1 - x_2
  \end{aligned}
\end{equation}

\section{Edge detection filter}
\label{sec:filter}
For edge detection we use a kernel with the width 7 pixels with coefficients
inversely proportional to distance to acentral element of the kernel. The
central element is determined by a property that all elements of the kernel sum
to zero:
\begin{equation}
  E_k = S \left\{
  \begin{array}{ll}
    -\sum\limits_{\substack{l \\ l \ne 0}} E_l & \quad k = 0 \\
    1 / \rho(k, 0) & \quad \text{otherwise.}
  \end{array}
  \right.
\end{equation}
For 3D case $S=172.96$ and for 2D case $S=30.46$ \cite{postnicov20232}.

\section{Influence of sample rotation on quality of computations}
\label{sec:rotqua}
\begin{figure*}[tp]
  \centering
  \subfigure[A sample of value noise]{
    \includegraphics[width=0.4\linewidth]{images/noise.png}
    \label{fig:roterror-noise}}
  \hfill
  \subfigure[Relative error of computation]{
    \includegraphics[width=0.4\linewidth]{images/roterror.png}
    \label{fig:roterror-error}}
  \caption[]{A plot of dependency of maximal pointwise relative error
    \cref{eq:relerr} in computation of correlation functions introduced by a
    rotation of the sample \cref{fig:roterror-noise} from the rotation
    angle. The rotation is performed around $Z$ axis counter-clockwise using
    nearest-neighbor interpolation.}
  \label{fig:roterror}
\end{figure*}
Our edge extraction filter works only for binary samples, therefore it is
natural to require that a rotated image remains binary. The simpliest way to do
so is to use nearest-neighbor interpolation when sampling subvoxel data during
rotation. As we show below, this results only in minimal precision loss in computation of
correlation functions.

Speculatively, the loss in precision should be minimal for three-point and
cluster correlation functions, because they are calculated
``in the whole volume'' of the sample. The biggest loss should be for $F_{sss}$
function because it takes into account only a small volume of the sample which
lies closely to the interface between phases and this volume is the only volume
affected by rotation.

To estimate the error introduced by rotation, consider a two-phase medium
\cref{fig:roterror-noise} whose void phase is defined by an inequality
$f(x, y, z) > U$ where $f$ is a value noise function
\cite[Section IV.B]{samarin2023robust} and $U$ is a threshold. We produce images
of the noise rotated around $Z$ axis by $\theta$ radians by discretizing an
inequation $f(p(x'), p(y'), p(z')) > U$ where:
\begin{equation*}
  \begin{aligned}
    x' &= x \cos \theta + y \sin \theta \\
    y' &= y \cos \theta - x \sin \theta \\
    z' &= z
  \end{aligned}
\end{equation*}
and
\begin{equation*}
  \begin{aligned}
    p(x) &= \left\{
    \begin{array}{ll}
      x'     & \quad x' < 1 \\
      2 - x' & \quad \text{otherwise}
    \end{array}
    \right. \\
    x ' &= x \mod 2.
  \end{aligned}
\end{equation*}
Therefore we assume the noise to be periodic with the period equal to $2$ and
the interface between phases is continuous. Discretizing this noise for
different values of $\theta \in [0, \pi/4]$ with two different resolutions we
obtain the first dataset which contains the best possible discretization of the
rotated noise at those resolutions. For this study we have produced images with
dimensionality $300 \times 300 \times 300$ and $600 \times 600 \times 600$
voxels (i.e., the second resolution is twice as much as the first).

The second dataset is constructed by discretizing the noise with $\theta = 0$ and
then rotating the discretized image using nearest-neighbor interpolation. This
procedure is done for the same two dimensionalities as in the first dataset.

We compute $S_3$ and $F_{sss}$ functions in periodic mode for the both datasets
and calculate pointwisely a relative error introduced by rotation as
\begin{equation}
  \varepsilon = \frac{|F_1 - F_2|}{F_1}
  \label{eq:relerr}
\end{equation}
where $F_1$ is a correlation function for a sample from the first dataset and
$F_2$ is a correlation function for a sample from the second dataset for the
same combination of a rotation angle $\theta$ and dimensionality $D$. Then we
calculate the maximal relative error as the maximum of all pointwise errors for
a given pair $(\theta, D)$.

Plots of maximal relative errors for functions $S_3$ and $F_{sss}$ are on
\cref{fig:roterror-error}. When calculating the error of the
surface-surface-surface function we omit values $F_{sss}(s_1, s_2)$ if either of
its arguments is less than 10 voxels because this function is undefined for
either $s_1$ or $s_2$ being equal to zero and our edge detection filter gives at
least 7 voxel transition zone where the correlation function is affected by this
indeterminacy. The maximal error for all $\theta$'s are 0.6\% for $S_3$ and 5.0\%
for $F_{sss}$ for dimensionality $300 \times 300 \times 300$ and 0.3\% for $S_3$
and 4.5\% for $F_{sss}$ for dimensionality $600 \times 600 \times 600$.

\section{Difference between rotation of the input image or the sampling pattern}
\label{sec:rotrot}
Let's take the noise from \cref{sec:rotqua} with lesser sizes of pores and
calculate $S_3$ function for it, preliminarily rotating the noise around Z-axis
counter-clockwise using nearest-neighbor interpolation (the first case) or
rotating the pattern around the same axis clock-wise (the second case). Then we
compute a difference between the results point-wise using a formula
\begin{equation}
  \varepsilon = 2\frac{|S_3^{(1)} - S_3^{(2)}|}{S_3^{(1)} + S_3^{(2)}}
  \label{eq:reldiff}
\end{equation}
The average of point-wise differences is at maximum for the angle of rotation
$\theta = \frac{\pi}{4}$ and equals to 0.8\%. The maximal difference is about
10\% for very small correlation length (about 2-3 pixels). These two methods of
rotating give minimal difference if applied to a homogeneous medium with an
average pore size much less than a size of the input (\cref{fig:rotdiff}).
\begin{figure*}[tp]
  \centering
  \subfigure[A sample of value noise with small pores]{
    \includegraphics[width=0.4\linewidth]{images/noise2.png}
    \label{fig:rotdiff-noise}}
  \hfill
  \subfigure[Difference between two methods of rotation]{
    \includegraphics[width=0.4\linewidth]{images/rotdiff.png}
    \label{fig:rotdiff-error}}
  \caption[]{A plot depicting difference between two rotation methods: rotation
    of the sample and of the pattern. Dependency of an average point-wise
    difference \cref{eq:reldiff} from a rotation angle is shown. The rotation is
    performed around $Z$ axis counter-clockwise (sample) and clockwise (pattern).}
  \label{fig:rotdiff}
\end{figure*}

\bibliography{paper}
\end{document}
