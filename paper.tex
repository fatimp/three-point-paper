\documentclass[reprint,amsmath,amssymb,aps,pre,showkeys,showpacs]{revtex4-1}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[export]{adjustbox}

\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
\newcommand{\highlight}[1]{{\color{red}{#1}}} % convinient for revised version

\begin{document}
\preprint{APS/123-QED}

\author{Vasily~Postnicov\textsuperscript{1}}
\author{Marina~V.~Karsanina\textsuperscript{1}}
\author{Aleksey~Khlyupin\textsuperscript{1,2}}
\author{Kirill~M.~Gerke\textsuperscript{1}}
\email{kg@ifz.ru}

\affiliation{\textsuperscript{1}Schmidt Institute of Physics of the Earth of
  Russian Academy of Sciences, Moscow, 107031, Russia}
\affiliation{\textsuperscript{2}Moscow Institute of Physics and Technology,
  Dolgoprudny, 141701, Russia}

\title{Evaluation of 3-point correlation functions from structural images on CPU
  and GPU architectures: accounting for anisotropy effects}

\begin{abstract}
  Wow, we can multiply arrays and tell you how cool it is.
\end{abstract}

\keywords{Arrays, multiplication, addition}

\maketitle

\section{Introduction}
Structures, or spatial arrangements of matter and energy, including some fields
(e.g., velocity or pressure) are ubiquitous in research applications and
frequently require description for subsequent analysis. Examples of such objects
for studies include galaxy formations \cite{springel2006}, immiscible multiphase
fluid flow patterns \cite{hopkins2015new,balashov2021}, rock and soil samples
\cite{rozenbaum2014,karsanina2015,ledesma2018,chen2020super,prokhorov2021digital,vogel2010},
food specimens \cite{derossi2019,nagdalian2021}, biological tissue
\cite{park2020}, vortexes during flow \cite{gorbunova2016precessing} and
interstellar turbulence \cite{portillo2018developing}. The scale of interest may
span orders of magnitude from angstroms and nm for materials
\cite{garum2020,gerke2021,khlyupin2023molecular} to millions of light-years for
star clusters \cite{takada2003three,hopkins2013stars}. The studied structure can
be non-static -- it will change with time, and this dynamics is usually also of
great interest \cite{jiao2013,fomin2023soil}. Thus, description of the structure
is of utmost importance for numerous applications:
\begin{enumerate}
  \item Elucidation of structure--property relationships in the form of
    theoretical expression \cite{Torquato_book,Sahimi_book}, e.g., rigorous
    bounds and such;
  \item Prediction of material physical properties using machine (deep) learning
    \cite{obayashi2018persistence,kamrava2020linking,roding2020predicting};
  \item Description of complex structures and fields for taxonomy, comparison
    and analysis
    \cite{takada2003three,hopkins2013stars,shivashankar2015felix,saadatfar2017pore,
      portillo2018developing,KarsaninaEJSS,PNM_Morse,khlyupin2023molecular},
    which may include temporal dynamics or surface evolution
    \cite{jiao2013,PhysRevE.92.023301,prokhorov2022,chen2022,fomin2023soil};
  \item Morphological representativity
    \cite{capek2009,rozenbaum2014,gerke2019tensor} and spatial stationarity
    analysis \cite{REVpaper,LavrukhinPRE};
  \item Stochastic reconstructions from limited amount of input data
    \cite{Adler_recon,Y-T,tahmasebiPRL,Euras2012,EPL2,karsaninaPRL,rozanski2023}
    in the form of limited dimension structures or correlation functions;
  \item Compress structural information for storage, analysis, training (feature
    extraction), and retrieval (by means of stochastic reconstructions)
    \cite{jiao2007,SciRep1,Havelka,KarsaninaEJSS};
  \item Multiscale image fusion that is usually necessary due to trade-off
    between field-of-view and imaging resolution
    \cite{SciRep1,Geoderma2018,chen2020super,karimpouli2022}.
\end{enumerate}

The number of possible descriptors to quantify spatial structure developed
within different disciplines is stunning, for example: phase ratio or porosity
\cite{anovitz2015characterization}, surface area, radial distribution functions
\cite{zimm1948scattering,becker2010radial}, Minkowski functionals
\cite{vogel2010} and tensors \cite{schroder2011minkowski}, correlation functions
\cite{Torquato_book}, persistence diagrams
\cite{shivashankar2015felix,saadatfar2017pore,obayashi2018persistence}. The
evolution of such metrics was mainly induced by the ease of measurement and
interpretation -- this is startling to observe holy wars on the question which
metric is superior to flare up occasionally,
e.g.,\cite{vogel2022holistic,yudina2023dual}. In fact, we need a single
universal descriptor defined by only one characteristic -- information
content. The latter is an ability of the metric to describe the structure at
hand with 100$\%$ meaning the ability to fully recover the structure back from
this metric. Thus, universal descriptor has to possess following key properties:
(1) high information content, (2) easy to assess, (3) high compression (i.e.,
descriptor is much "smaller" than the structure itself).

The large portion of the research papers mentioned above
\cite{rozenbaum2014,karsanina2015,ledesma2018,derossi2019,portillo2018developing,
  takada2003three,hopkins2013stars,jiao2013,Torquato_book,roding2020predicting,
  KarsaninaEJSS,capek2009,gerke2019tensor,REVpaper,LavrukhinPRE,Adler_recon,Y-T,
  tahmasebiPRL,Euras2012,EPL2,karsaninaPRL,jiao2007,SciRep1,Havelka,Geoderma2018}
is based on so-called correlation functions (CFs). These functions define a
probability that some events are occurring withing the structure (with some
special cases of surface functions), for example, 2-point probability $S_2$
measures the probability that both ends of the line segment are within the same
phase, 2-point cluster function $C_2$ -- that both ends of the line segment are
within the same interconnected cluster of same phase, and lineal path $L_2$
measures the probability that the whole segment lies within the phase (see
\highlight{Fig.1}). Compared to other descriptors, CFs possess a number of
features making them, in our opinion, a perfect candidate for universal
descriptor:
\begin{enumerate}
  \item They contain the majority of other metrics inside. For example, porosity
    is $S_2(0)$ (and at zero correlation length of the majority of correlation
    functions except for surface ones), surface area is represented by in the
    derivative at $S_2(0)$ \cite{debye1957scattering} or the value of
    $F_{ss}(0)$ (or $F_{sss}(0)$). Connectivity is described by cluster
    functions $C_2$ or $C_3$. Pore-size distribution is related to pore-size
    function and partially by $L_2$ and $S_3$. Surface-void functions are
    interconnected with mean curvature and Euler characteristic
    \cite{ma2020generation}. All together, the classic set of correlation
    functions describes both the geometry and topology of the structure at hand;
  \item While the extent to which such classical set describes any arbitrary
    structure is not yet known, compared to other complex descriptors where are
    known pathways to assess the information content of correlation functions --
    there is a methodology for $S_2$ \cite{Gommes2} and approaches for other
    functions \cite{Degeneraty.045306,cherkasov2023towards};
  \item In addition to a possibility to compute correlation functions using
    images or other structural data, i.e., similar to all other descriptors,
    some CFs can be also determined experimentally
    \cite{debye1957scattering,barrall1992nmr,dietrich1995scattering,li2018accurate};
  \item Correlation functions can be scaled \cite{karsaninaPRL} or manipulated,
    for example, to add functions into a single one \cite{moctezuma2002};
  \item As opposed to scalar metrics such as porosity, surface area or Minkowski
    functionals, CFs can be computed in directions and describe anisotropic
    structures;
  \item Numerous rigorous bounds to obtain thermal, elastic, electromagnetic and
    transport properties are known, among which the most known (and least useful
    due to the impractically huge gap between the bounds) are Hashin-Strikman
    bounds \cite{hashin1963variational}. Other expressions based on integration
    of higher order $S_n$ are known and were found to be close to direct
    simulations
    \cite{brown1955solid,beran1965use,milton1981bounds,hlushkou2015effective};
  \item One can control both the size of the CFs-based descriptor and the
    information content via correlation length, number of functions in the set
    (including directions \cite{EPL2}), and by the order of functions (e.g., 2-
    and 3-point versions, or even more points).
\end{enumerate}
This list highlights that correlations functions are indeed possess necessary
properties so satisfy key criteria stated above.

However, while 2-point CFs are computed and used in multitude of studies, higher
order functions, for example, 3-point correlation functions are not that widely
used. The reason for this is straightforward -- 3-point correlation functions
are more involved and, thus, require much more computational resources to
assess. It has been shown that the amount of additional information content with
each increase in number of points $n$ decreases \cite{yao1993high,Gommes2}. The
trade-off between additional information and computational burden is still not
clear. Nonetheless, the computation of 3-point statistics is known to be
advantageous at least in the number of applications as related to cosmology,
astrophysics and turbulence patterns analysis as they can probe non-Gaussian
signatures in the distribution of matter and energy, which are not captured in
2-point counterparts
\cite{TakadaJain,hopkins2013stars,gorbunova2016precessing,yoo2022non}.

In this contribution we continue our initiative to develop a simple, efficient
and open-source solution to compute all classical correlation functions on CPU
and GPU architectures -- \code{CorrelationFunctions.jl} \cite{CFsjlpaper}. Here
we build upon previous results in computations of higher order functions with
$n > 2$, most notably by Malmir et al. \cite{malmir2018}, and our aim is to
develop robust and computationally efficient methods. In addition, we also
considered the case of anisotropic structures and how to describe them with
3-point correlation functions similar to directional 2-point CFs
\cite{10.1063/1.4867611,EPL1}.

The paper is organized as follows: in \cref{sec:methods} we provide
mathematical background and describe methods for computation of 3-point
correlation functions. Verification of these methods along with some results for
real-world samples (sandstone, soil etc.) is described in
\cref{sec:results}. Section \ref{sec:discussion} provides the discussion, a
comparison with other existing methods and summarizes possible directions for
improvement.

\section{Methods}
\label{sec:methods}
\subsection{3-point correlation functions}
Let $A_1, A_2, \dots, A_n$ be pairwise disjoint subsets of a set
$A \subset \mathbb{R}^n$, where the index can be interpreted as a phase on the
image $A$. We introduce a family of indicator functions
$I_n(x) : A \rightarrow \{0,1\}$ defined as:
\begin{equation}
  I_n(x) = \left\{
  \begin{array}{ll}
    1 & \quad x \in A_n \\
    0 & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation}

Now we can define the three-point correlation function
$S_3: \mathbb{R}^{2n} \rightarrow [0, 1]$:
\begin{equation}
  S_3^n(x_1, x_2) = \langle I_n(x) I_n(x + x_1) I_n(x + x_2) \rangle
\end{equation}
where $\langle \dots \rangle$ means average over all points in $A$. It can be
understood as the probability that all three vertices of a triangle
$(0, x_1, x_2)$ will appear in the subset $A_n$ when the triangle is randomly
thrown in $A$. When $A$ represent isotropic medium, $x_1$ and $x_2$ can be
replaced with three numbers $r_1 = |x_1|$, $r_2 = |x_2|$ and $r_3 = |x_2 - x_1|$
to get a function of three scalar arguments.

Another function closely related to the three-point correlation function is the
cluster function which can be defined as:
\begin{equation}
  C_3^n(x_1, x_2) = \sum_{k=1}^K \langle \tilde{I}_k(x) \tilde{I}_k(x + x_1)
  \tilde{I}_k(x + x_2) \rangle
\end{equation}
where $\tilde{I}_k$ is an indicator function for $k$-th cluster and $K$ is a
total number of clusters. A cluster is a subset of $A_n$ so that any two points
in this subset can be connected with a curve belonging to that subset.

Introduce a function $M_n(x) = |\nabla I_n(x)|$ which is a so-called interface
indicator function. With this function we can define three additional
correlation functions, which are the surface-surface-surface function
($F_{sss}$), surface-surface-void function ($F_{ssv}$) and surface-void-void
function ($F_{svv}$). They are defined as:
\begin{align}
  F_{sss}^n(x_1, x_2) &= \langle M_n(x) M_n(x + x_1) M_n(x + x_2) \rangle \\
  F_{ssv}^n(x_1, x_2) &= \langle M_n(x) M_v(x + x_1) I_v(x + x_2) \rangle \\
  F_{svv}^n(x_1, x_2) &= \langle M_n(x) I_v(x + x_1) I_v(x + x_2) \rangle
\end{align}
Here $I_v$ is an indicator function for the subset of the void phase
$A_v$. Unlike $S_3$ and $C_3$ functions, these functions do not have the meaning
of probability and have the units of measurement inversely proportional to
volume, surface and length, respectively (e.g. $\mu m^{-3}$, $\mu m^{-2}$ and
$\mu m^{-1}$). These functions describe the interface of the subset $A_n$ and
its spatial configuration with respect to $A_v$.

\subsection{Computational algorithms}
Three-point correlation function $S_3$ can be computed either in spatial domain
or in frequency domain via the convolution theorem. Suppose that a finite
countable set $A$ is defined as a multidimensional array. A point $x$ belongs to
a subset $A_n$ if and only if $A[x] = n$. The simplest algorithm below
calculates $S_3$ pointwise in spatial domain:
\begin{algorithmic}[1]
  \Procedure{$S_3$}{$A, n, x_1, x_2$}
  \State $A_n \gets I_n (A)$
  \Comment Apply $I_n$ to the input array elementwise.
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A''_n \gets \mathfrak{S}_{x_2}(A_n)$
  \State $T \gets A_n \cdot A'_n \cdot A''_n$
  \State \textbf{return} $Sum(T) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}
In this algorithm the indicator function $I_n$ for the phase of interest $n$ is
applied to the input array $A$. Then the shift operator $\mathfrak{S}$ is used
to shift $A_n$ by vectors $x_1$ and $x_2$. Finally, the three arrays are
multiplied pointwise and a normalized sum of all elements of the product is
returned.

There are two common boundary conditions when applying $\mathfrak{S}$. The
first condition is to extend $A_n$ periodically (\cref{fig:s3-periodic}) when
accessing out-of-bounds array elements. In this case $\mathfrak{S}_z$ is a
circular shift operator:
\begin{equation}
  A[x] \leftarrow A[x+z \mod d]
\end{equation}
In this case $Norm(A, x_1, x_2)$ does not depend on $x_1$ and $x_2$ and
is equal to the total number of elements in $A$. The second condition is to
replace out-of-bound elements with zeros (so-called zero padding)
(\cref{fig:s3-zeros}). A formula for $Norm(A, x_1, x_2)$ in this case is in
\ref{sec:number-of-trials} and $\mathfrak{S}_z$ is defined as follows:
\begin{equation}
  A[x] \leftarrow \left\{
  \begin{array}{ll}
    A[x+z] & \quad \text{if $x+z$ is a correct index in $A$} \\
    0 & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation}
\begin{figure*}[tp]
  \centering
  \subfigure[Periodic boundary conditions]{
    \includegraphics[width=0.4\linewidth]{images/periodic.png}
    \label{fig:s3-periodic}}
  \hfill
  \subfigure[Zero padding]{
    \includegraphics[width=0.4\linewidth]{images/zeros.png}
    \label{fig:s3-zeros}}
  \caption[]{Computation of unnormalized $S_3$ function at point $(1, 2)$ for
    one-dimensional sequence of length 8.}
  \label{fig:s3-computation}
\end{figure*}

The second approach is to compute the whole correlation map in Fourier
domain. Suppose we have a function
$f: \mathbb{R} \rightarrow \mathbb{R}$. Triple correlation for this function is:
\begin{equation}
  g(t_1, t_2) = \int f(\tau) f(\tau + t_1) f(\tau + t_2) d \tau.
\end{equation}
We can use a well-known formula to compute Fourier image of $g$:
\begin{equation}
  \hat{g}(z_1, z_2) = \hat{f}(z_1) \hat{f}(z_2) \overline{\hat{f}(z_1 + z_2)}
\end{equation}
This algorithm has a better computational complexity compared with the previous
algorithms if the whole correlation map is needed ($O(n^2 \log n)$ vs
$O(n^3)$ where $n$ is a number of elements in the input array). The whole
correlation map, however, requires a lot of memory and is rarely
needed. Imagine, that the input array $A$ is of dimensions $500 \times 500$.
Then, considering that single precision floating point numbers are used,
$4 \cdot 2 \cdot 500^4 / 1000^3 = 500$ GB are needed to store Fourier image of
the map. Moreover, Fourier image of the whole map is needed even if only one
element of the map in spatial domain is required. The aforementioned limitations
render this approach impractical.

Our implementation fixes $x_1$ and $x_2$ to be parallel to one of the axes $X$,
$Y$ or $Z$ with restriction $x_1 \perp x_2$ (\cref{fig:pattern}). Thus, the
output has dimensions $D_1 \times D_2$ where $D_1$ and $D_2$ are dimensions of
the input array along selected axes.
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\linewidth]{images/pattern.png}
  \caption[]{The pattern used for calculation of $S_3$ function in our
    implementation. Vectors $x_1$ and $x_2$ are parallel to one of the axes $X$,
    $Y$ or $Z$ and have lengths $r_1$ and $r_2$ respectively. A red triangle
    contributes to $S_3(2, 6)$ and blue triangles contribute to $S_3(1, 1)$.}
  \label{fig:pattern}
\end{figure}

Algorithms for three-point surface functions are the same as for $S_3$,
containing only small modifications. The main difference is that we need to
replace an indicator function $I_n$ with an edge detection operator $E_n$
(see \ref{sec:filter}). Then the algorithms are straightforward:
\begin{algorithmic}[1]
  \Procedure{$F_{sss}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A''_n \gets \mathfrak{S}_{x_2}(A_n)$
  \State $T \gets A_n \cdot A'_n \cdot A''_n$
  \State \textbf{return} $Sum(T) / Norm(A, x_1, x_2)$
  \EndProcedure

  \Procedure{$F_{ssv}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A_{(void)} \gets I_{(void)} (A)$
  \State $A'_n \gets \mathfrak{S}_{x_1}(A_n)$
  \State $A'_{(void)} \gets \mathfrak{S}_{x_2}(A_{(void)})$
  \State $T \gets A_n \cdot A'_n \cdot A'_{(void)}$
  \State \textbf{return} $Sum(T) / Norm(A, x_1, x_2)$
  \EndProcedure

  \Procedure{$F_{svv}$}{$A, n, x_1, x_2$}
  \State $A_n \gets E_n (A)$
  \State $A_{(void)} \gets I_{(void)} (A)$
  \State $A'_{(void)} \gets \mathfrak{S}_{x_1}(A_{(void)})$
  \State $A''_{(void)} \gets \mathfrak{S}_{x_2}(A_{(void)})$
  \State $T \gets A_n \cdot A'_{(void)} \cdot A''_{(void)}$
  \State \textbf{return} $Sum(T) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}

Input images must have appropriately high resolution for edge detection filter
to work correctly. A criterion for ``goodness'' of an image can be expressed
with $C_{\alpha}$ parameter \cite{samarin2023robust}. Let $\alpha \in [0, 1]$
and $f(x)$ be (band-limited) input image ($x \in \mathbb{R}^2$ or
$\mathbb{R}^3$). We define $C_\alpha$ as follows:
\begin{equation}
  \begin{aligned}
    f_0(x) &= f(x) - \langle f(x) \rangle \\
    C_\alpha &= \frac{\int_{-\alpha\omega}^{\alpha\omega} |\hat{f_0}(z)|^2
      dz}{\int_{-\omega}^{\omega} |\hat{f_0}(z)|^2 dz}
  \end{aligned}
\end{equation}
where $\hat{f_0}$ is a Fourier transform of $f_0$ and $\omega$ is a folding
frequency which depends only on resolution of the image. If a criterion
$C_{0.5} > 0.97$ holds then the image is suitable for application of
aforementioned algorithms for calculation of surface functions, otherwise
image's resolution can be improved with the help of interpolation prior to
computations \cite{samarin2023robust}.

To compute $C_3$ function we need to use a connected-component labeling
algorithm \cite{4728561,PhysRevB.14.3438} to label clusters. Then, again, a
slightly modified algorithm for $S_3$ is used to assess cluster function:
\begin{algorithmic}[1]
  \Procedure{$C_3$}{$A, n, x_1, x_2$}
  \State $A_n \gets I_n (A)$
  \State $C_n \gets \mathfrak{C}(A_n)$
  \State $C'_n \gets \mathfrak{S}_{x_1}(C_n)$
  \State $C''_n \gets \mathfrak{S}_{x_2}(C_n)$
  \State $T \gets C_n \odot C'_n \odot C''_n$
  \State \textbf{return} $Sum(T) / Norm(A, x_1, x_2)$
  \EndProcedure
\end{algorithmic}
Here $\mathfrak{C}$ is connected-component labeling operator and $\odot$ is
defined as follows:
\begin{equation}
  x \odot y = \left\{
  \begin{array}{ll}
    1 & \quad x = y \\
    0 & \quad \text{otherwise}.
  \end{array}
  \right.
\end{equation}

\subsection{Analysis of anisotropic media}
When an analized sample is anisotropic, i.e. it is stretched or oriented along
some specific direction, it may be desired to align one of the catheti of the
scanning pattern \cref{fig:pattern} with that direction. In this case the
anisotropy present in the sample will be featured in a produced correlation
function \textcolor{red}{most well. voobshe eto po-angliyski?}

To detect the direction of anisotropy we use an $N \times N$ (where $N$ is
dimensionality of the sample) covariance matrix for coordinates of points in the
phase of interest:
\begin{equation}
  C_{ij} = \sum_{x \in \left\{
    \begin{array}{l}
      \text{Coordinates of points} \\
      \text{in the phase of interset}
    \end{array}
    \right\}} (x_i - \overline{x_i})(x_j - \overline{x_j})
\end{equation}
and decompose $C$ as $T \Lambda T^{-1}$ where $T$ is a unitary matrix and
$\Lambda$ is diagonal. $T$ can always be made so that it defines a rotation (by
multiplication of one of the columns by $-1$ if needed, so that
$\det T = 1$. Application of this rotation to the sample makes the direction of
anisotropy parallel to one of the axes, so anisotropy can be better featured in
the correlation function \cref{fig:aniso}.
\begin{figure*}[tp]
  \centering
  \subfigure[An original image of an anisotropic pore.]{
    \includegraphics[width=0.4\linewidth, frame]{images/aniso.png}
    \label{fig:aniso-unrot}}
  \hfill
  \subfigure[A rotated image of the pore, so it is elongated along the axis
    $X$.]{
    \includegraphics[width=0.4\linewidth, frame]{images/aniso-rot.png}
    \label{fig:aniso-rot}}
  \vskip\baselineskip
  \subfigure[$S_3$ function for the original image]{
    \includegraphics[width=0.3\linewidth]{images/aniso-s3.png}}
  \hfill
  \subfigure[$S_3$ function for the rotated image. A vector $(0.92, -0.4)$ is a
    direction of elongation of the pore.]{
    \includegraphics[width=0.3\linewidth]{images/aniso-rot-s3.png}
    \label{fig:aniso-rot-s3}}
  \hfill
  \subfigure[$S_3$ function averaged across 100 random rotations.]{
    \includegraphics[width=0.3\linewidth]{images/aniso-avg-s3.png}
    \label{fig:aniso-avg}}
  \caption[]{Behaviour of our algorithm for calculation of the $S_3$ function
    when dealing with highly anisotropic media. The pattern \cref{fig:pattern}
    which we use in our algorithm is most sensitive to anisotropy which is
    directed along one of the axes. A result on \cref{fig:aniso-avg} averaged
    across rotations is similar to the algorithm proposed by Malmir~et~al.}
  \label{fig:aniso}
\end{figure*}
The above said holds for every algorithm introduced in the paper.

When a sample is known to be isotropic, the correlation function may be
calculated multiple times, each time applying a random rotation of the sample,
and then averaged across rotations to gather more statistics. This process is
illustrated on \cref{fig:workflow}.
\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.6\linewidth]{images/workflow.png}
  \caption[]{A possible workflow for computation of correlation functions
    (clockwise from top left to bottom right ): 1.~rotating a sample in random
    directions (which is equivalent to rotating the sampling pattern),
    2.~calculating the correlation function for each direction, 3.~avegaring
    results across rotations, 4.~representing the result as a family of 2D
    plots.}
  \label{fig:workflow}
\end{figure*}

\section{Results}
\label{sec:results}
\subsection{Verification}
To verify correctness of computation of $S_3$ and $C_3$ functions we use the
following simple relations:
\begin{align}
  S_3^n (x, 0) = S_3^n (0, x) &= S_2^n(x) \\
  C_3^n (x, 0) = C_3^n (0, x) &= C_2^n(x) \\
  \lim_{\substack{x_1 \to \infty \\ x_2 \to \infty}} S_3^n (x_1, x_2) &= \phi_n^3
\end{align}
Here $\phi_n$ is a fraction of phase $n$ in $A$.

There are only few sets for which analytic expressions for $S_2$ are known. One
of those is a set consisting of overlapping balls with a fixed radius $R$ and
centers generated with Poisson process with parameter $\lambda$. In this case
the expression for $S_2$ is following:
\begin{equation}
  \begin{aligned}
    S_2(r, R) &= \exp(-\frac{4}{3}\pi\lambda R^3 f(r, R)) \\
    f(r, R) &= \left\{
    \begin{array}{ll}
      1 + \frac{3}{4} \frac{r}{R} - \frac{1}{16} (\frac{r}{R})^3 & \quad r < 2R \\
      2 & \quad \text{otherwise}.
    \end{array}
    \right.
  \end{aligned}
  \label{eq:s2-balls}
\end{equation}

On \cref{fig:balls} there is an intersection of such a set with $R = 0.02$ and
$\lambda=5000$ and a cube $[0, 1]^3$. Because $R \ll 1$, we can use
\cref{eq:s2-balls} to verify our computations -- this is exactly what we present on
\cref{fig:balls-s3-comparison}.
\begin{figure*}[tp]
  \centering
  \subfigure[Realization of overlapping balls]{
    \includegraphics[width=0.4\linewidth]{images/balls.png}
    \label{fig:balls}}
  \hfill
  \subfigure[A plot of $S_3(0, r)$ computed with our algorithm and theoretical
    formula.]{
    \includegraphics[width=0.4\linewidth]{images/balls-s3.png}
    \label{fig:balls-s3-comparison}}
  \caption[]{A comparison of calculated and theoretical values of $S_3$ function
    for overlapping balls.}
  \label{fig:s3-verification}
\end{figure*}

To test $F_{sss}$ function we use a recently developed approach which computes
that function for sets defined by inequality $f(x) \le T$, $x \in \mathbb{R}^3$
with help of automatic differentiation \cite{postnicov20232}. We choose $f$ as:
\begin{equation}
  f(x, y, z) = y^2 + z^2 - a x^2 (b^2 - x^2)
\end{equation}
and parameters $a = 10$, $b = 0.45$, $T = 10^{-2}$, so inequation
$f(x, y, z) \le T$ gives us a dumbbell-like object (\cref{fig:sss-dumbbell}).

The test is performed by firstly evaluating the inequation in a cube
$[-1, 1]^3$ and obtaining precise values of $F_{sss}$ and secondly computing
$F_{sss}$ with our algorithm, giving a discretized $400 \times 400 \times 400$
pixels wide image as the input. $F_{sss}$ function is evaluated in $XY$
plane. Pointwise relative error of $F_{sss}$ is on
\cref{fig:sss-dumbbell-error}. Maximal relative error in the area distanced
farther than 0.1 (20 pixels) from curves of discontinuity (see
\cref{fig:sss-dumbbell-precise}) is no more than 20\%.
\begin{figure*}[tp]
  \centering
  \subfigure[The dumbbell-like object used in testing of $F_{sss}$ computation]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell.png}
    \label{fig:sss-dumbbell}}
  \hfill
  \subfigure[Relative error of computation]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-err.png}
    \label{fig:sss-dumbbell-error}}
  \vskip\baselineskip
  \subfigure[$F_{sss}$: precise. The correlation function is undefined (has type
    II discontinuity) at curves A, B and C.]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-precise.png}
    \label{fig:sss-dumbbell-precise}}
  \hfill
  \subfigure[$F_{sss}$: calculated with our approach]{
    \includegraphics[width=0.4\linewidth]{images/dumbbell-sss-julia.png}}
  \caption[]{A comparison of $F_{sss}$ function calculated using our approach
    with its precise values.}
  \label{fig:sss-verification}
\end{figure*}

To test $F_{ssv}$ and $F_{svv}$ we use the following relations for such a set
$A$ where all non-void phase is covered by a ball with radius $R$:
\begin{align}
  F^n_{ssv}(x_1, x_2) &= F^n_{ss}(x_1) \qquad x_2 > R \\
  F^n_{svv}(x_1, x_2) &= F^n_{sv}(x_1) \qquad x_2 > R
\end{align}
$F_{ss}$ and $F_{sv}$ functions are well-known for a ball of radius $R$ (solid
phase) placed in the center of cube of volume $V$ (void phase):
\begin{align}
  F_{ss}(r, R) &= \frac{1}{V} \left\{
    \begin{array}{ll}
      2\pi R^2/r & \quad r < 2R \\
      0 & \quad \text{otherwise}
    \end{array}
    \right.\\
  F_{sv}(r, R) &= \frac{1}{V} \left\{
    \begin{array}{ll}
      \pi Rr + 2\pi R^2 & \quad r < 2R \\
      4\pi R^2 & \quad \text{otherwise}
    \end{array}
    \right.
\end{align}
The comparison of our algorithm against theory is shown on
\cref{fig:surface-verification}. Radius of the ball is chosen to be $R=0.2$.
\begin{figure*}[tp]
  \centering
  \subfigure[$F_{ssv}$]{
    \includegraphics[width=0.4\linewidth]{images/ball-ssv.png}
    \label{fig:balls-ssv}}
  \hfill
  \subfigure[$F_{svv}$]{
    \includegraphics[width=0.4\linewidth]{images/ball-svv.png}
    \label{fig:ball-svv}}
  \caption[]{Comparison of $F_{ssv}$ and $F_{svv}$ functions for a ball with the
    radius $0.2$ with theoretical values.}
  \label{fig:surface-verification}
\end{figure*}

\subsection{Applications to material images}
\begin{table*}[!htp]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    Sample name & Image type & Dimensions (pixels) & Image resolution ($\mu m$) & $C_{0.5}$\\
    \hline
    Sandstone & XCT &  $500 \times 500 \times 500$ & 2.25 & 0.9703 \\
    Soil & XCT & $160 \times 160 \times 160$ & 2.25 & 0.9210 \\
    Shale & XCT & $160 \times 160 \times 160$ & 2.25 & 0.8912 \\
    Sandstone & SEM &  $1280 \times 869$ & 0.10 & 0.9703 \\
    \hline
  \end{tabular}
  \caption{Summary of samples used for calculation of correlation functions.}
  \label{tab:summary}
\end{table*}
In this section we compute correlation functions for 2- and 3-dimensional real
samples. Table \ref{tab:summary} contains information about these samples. Note
that we compute surface correlation functions only for those samples for which
the criterion $C_{0.5} > 0.97$ holds (the two sandstones and the \textcolor{red}{shale}). Images
of the samples are on \cref{fig:samples}. On plots of correlation functions for
isotropic samples we provide a family of curves with the first argument of the
correlation function being fixed. For anisotropic samples we provide heatmaps of
correlation functions where anisotropy can be easily observed.
\begin{figure*}[tp]
  \centering
  \subfigure[Sanstone XCT]{
    \includegraphics[width=0.4\linewidth]{images/15581.png}
    \label{fig:sample-sandstone-xct}}
  \hfill
  \subfigure[Sandstone SEM (different clusters of void phase are shown in color)]{
    \includegraphics[width=0.4\linewidth, frame]{images/sandstone1.png}
    \label{fig:sample-sandstone}}
  \vskip\baselineskip
  \subfigure[Soil]{
    \includegraphics[width=0.4\linewidth]{images/soil.png}
    \label{fig:sample-soil}}
  \hfill
  \subfigure[Shale]{
    \includegraphics[width=0.4\linewidth]{images/shale.png}
    \label{fig:sample-shale}}
  \caption[]{Images of samples used for calculation of higher-order correlation
    functions.}
  \label{fig:samples}
\end{figure*}

Correlation functions for the XCT sample of a sandstone are on
\cref{fig:sample-sandstone-xct-cf}. The plot of $S_3$ function allows us to
estimate porosity of the sample to be $\sim 0.19$ (note that the curve with
$r_1 = 0$ is actually $S_2$ function). The two-point correlation function
reaches plateau at $r_2 \approx 60 \mu m$ which means that two events
of finding two points in the void phase are independent if the points are
farther than $60 \mu m$ from each other. We see that the sample is isotropic
($S_3(0, 56.25) \approx S_3(56.25, 0)$). From similarity of the $C_3$ and $S_3$
functions it can be stated that the pore phase in this sample forms one big
interconnected pore system.

Correlation functions for the SEM sample (the sandstone) are on
\cref{fig:sample-sandstone-cf}. Porosity of the sample is $\sim 0.3$ as follows
from the plot of $S_3$ function at $r_1 = 0$. The function $S_3(0, r_2)$ reaches
plateau at $r_2 \approx 20\ \mu m$. The sample is highly anisotropic (elongated
along the ordinate). The samples has clusters which are $\sim 45\ \mu m$ in
diameter.

The anisotropic samples (the soil and the shale) were preliminarily rotated with
periodic boundary conditions to align elongated pores with coordinate axes. The
result of rotation can be seen on \cref{fig:samples-rot}. Heatmaps of $S_3$
function for these samples can be seen on \cref{fig:heatmaps}. It can be
observed that elongated clusters of the void phase in the sample of soil form a
structure which resembles a regular grid with spacing of about $60 \mu m$. The
sample of shale shows less regular yet still anisotropic structure.

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.4\linewidth]{images/15581-surf3.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/15581-surf2void.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/15581-surfvoid2.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/15581-s3.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/15581-c3.png}
  \caption[]{Correlation functions for the sandstone XCT sample
    (\cref{fig:sample-sandstone-xct}).}
  \label{fig:sample-sandstone-xct-cf}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-surf2void.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-surfvoid2.png}
  \vskip\baselineskip
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-s3.png}
  \hfill
  \includegraphics[width=0.4\linewidth]{images/sandstone1.png-c3.png}
  \caption[]{Correlation functions for the sandstone SEM sample
    (\cref{fig:sample-sandstone}).}
  \label{fig:sample-sandstone-cf}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \subfigure[Soil]{
    \includegraphics[width=0.4\linewidth]{images/soil-rot.png}}
  \hfill
  \subfigure[Shale]{
    \includegraphics[width=0.4\linewidth]{images/shale-rot.png}}
  \caption[]{Rotations of anisotropic samples with pores aligned with the
    coordinate axes.}
  \label{fig:samples-rot}
\end{figure*}

\begin{figure*}[tp]
  \centering
  \subfigure[Soil]{
    \includegraphics[width=0.4\linewidth]{images/soil-s3.png}
    \label{fig:soil-s3}}
  \hfill
  \subfigure[Shale]{
    \includegraphics[width=0.4\linewidth]{images/shale-s3.png}
    \label{fig:shale-s3}}
  \caption[]{Heatmaps of $S_3$ function for highly anisotropic samples of shale
    and soil.}
  \label{fig:heatmaps}
\end{figure*}

\section{Discussion}
\label{sec:discussion}
In this paper we have provided two approaches to compute three-point correlation
function:
\begin{enumerate}
\item Computation in frequency domain using Fourier transform. This approach has
  computational complexity $O(n^2 \log n)$ and computes the whole correlation
  map. Unfortunately, it requires $O(n^2)$ additional memory and therefore can
  be used only with small inputs. Moreover, the whole Fourier image of the input
  is needed even if we need only a small part of the correlation map.
\item Computation in spatial domain. This approach is implemented by us in
  CorrelationFunctions.jl package. This approach calculates the full map with
  complexity $O(n^3)$ but uses only $O(n)$ additional memory for shifted
  versions of the input. For our purposes the whole map is not needed and
  therefore the amount of calculations can be significantly reduced.
\end{enumerate}
It's tempting to create an algorithm which unites advantages of both approaches
(fast speed of the first and low memory consumption of the second) which
computes some desired slices of correlation map. It is known that Fourier
transform is the only linear transform which allows computation of convolution
in linear time. It is still an open question if there are linear transforms which
allow computation of convolution faster than a naïve approach
\cite{stone2008uniqueness,stone1998convolution}.

\textcolor{red}{Where to put this?}
We have made a comparison of our algorithm with two algorithms, one of which
proposed by Malmir~et~al \cite{malmir2018} and another proposed by Smith and
Torquato \cite{SMITH1988176}. The first algorithms generates a triangle with
fixed sides $r_1$ and $r_2$ and an arbitrary angle $\theta$ between them and
places it in the medium firstly making a random translation and a rotation
around a random vector by a random angle. By making a large number of trials the
algorithm gets a value of a three-point correlation function at the point
$(r_1, r_2, \theta)$. The second algorithm takes a precalculated triangle
$(r_1, r_2, \theta)$ from a web-like pattern and places it in the medium without
rotation, only applying a random translation. This way the algorithm preserves
orientation of triangles stored in the pattern. The main advantage of our
algorithm is its parallelizability and ease of implementation. A drawback is
that an angle between catheti of the sampling pattern is fixed to be
$\theta = \frac{\pi}{2}$ but the pattern can be rotated as a whole by an
equivalent operation of rotation of a sample. These rotations can be random as
in the Malmir's algorithm (\cref{fig:aniso-avg}), or it can be a single rotation
to align catheti of the sampling triangle with the direction of anisotropy
(\cref{fig:aniso-rot-s3}).

We mentioned that classic set of correlation functions describes
both the geometry and topology of the structure at hand -- but this is to yet
unknown extent. With the advent of analytical methods
\cite{cherkasov2023towards} to assess information content of arbitrary
descriptor for structure of any size, it will be possible to choose the most
useful set of correlation functions and compare their information content
against classical and other metrics.

\appendix
\section{Computation of number of trials for non-periodic mode}
\label{sec:number-of-trials}
If the displacement vectors $x_1, x_2: x_1 \perp x_2$ are parallel to two
distinct unit vectors $i=(1,0,0)$, $j=(0,1,0)$ or $k=(0,0,1)$ then the number of
trials for the input array having dimensions $D = (D_x, D_y, D_z)$ is the
following:
\begin{equation}
  \begin{aligned}
    & Norm(A, x_1, x_2) = \prod_k D'_k \\
    & D' = D - x_1 - x_2
  \end{aligned}
\end{equation}

\section{Edge detection filter}
\label{sec:filter}
For edge detection we use a kernel with the width 7 pixels with coefficients
inversely proportional to distance to acentral element of the kernel. The
central element is determined by a property that all elements of the kernel sum
to zero:
\begin{equation}
  E_k = S \left\{
  \begin{array}{ll}
    -\sum\limits_{\substack{l \\ l \ne 0}} E_l & \quad k = 0 \\
    1 / \rho(k, 0) & \quad \text{otherwise}
  \end{array}
  \right.
\end{equation}
For 3D case $S=172.96$ and for 2D case $S=30.46$ \cite{postnicov20232}.

\bibliography{paper}
\end{document}
